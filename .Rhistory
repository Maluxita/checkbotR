x[y==1,]=x[y==1,] + 1
x
y
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
#Se construye un Data.Frame
dat=data.frame(x=x, y=as.factor(y))
dat
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
dat=data.frame(x=x, y=as.factor(y))
dat
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
svmfit=svm(y~., data=dat, kernel="linear", cost=10)
plot(svmfit,dat)
svmfit$index
summary(svmfit)
svmfit=svm(y~., data=dat, kernel="polynomial", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="sigmoid", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="sigmoid", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="radial", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="sigmoid", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="radial", cost=10)
plot(svmfit, dat)
library(kernlab)
data(spam)
index=sample(1:nrow(spam),100)
index
fm=ksvm(type~.,data=spam[-index,],kernel="rbfdot",kpar="automatic",C=60,cross=5)
fm
pred=predict(fm,spam[index,])
table(pred,spam[index,58])
fm=ksvm(type~.,data=spam[-index,],kernel="polydot",kpar="automatic",C=60,cross=5)
pred=predict(fm,spam[index,])
table(pred,spam[index,58])
library(topicmodels)
data("AssociatedPress")
AssociatedPress
print(model)
summary(model)
model <- svm(Species ~ ., data = iris)
# alternatively the traditional interface:
x <- subset(iris, select = -Species)
y <- Species
x
y
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
#Se construye un Data.Frame
dat=data.frame(x=x, y=as.factor(y))
plot(x, col=(y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
plot(x, col=(y-9),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
x <- subset(iris, select = -Species)
y <- Species
model <- svm(x, y, probability = TRUE)
dat=data.frame(x=x, y=as.factor(y))
dat
plot(x, col=(y-9),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
x <- subset(iris, select = -Species)
plot(x, col=(y-9),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
print(model)
summary(model)
pred <- predict(model, x)
pred <- fitted(model)
pred <- predict(model, x, decision.values = TRUE, probability = TRUE)
attr(pred, "decision.values")[1:4,]
attr(pred, "probabilities")[1:4,]
plot(x, col=(y-9),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
plot(x, y,main="Datos mezclados",xlab="Eje X",ylab="Eje y")
library(e1071)
data(iris)
attach(iris)
## classification mode
# default with factor response:
model <- svm(Species ~ ., data = iris)
# alternatively the traditional interface:
x <- subset(iris, select = -Species)
y <- Species
model <- svm(x, y, probability = TRUE)
print(model)
summary(model)
## classification mode
# default with factor response:
model <- svm(Species ~ ., data = iris)
# alternatively the traditional interface:
x <- subset(iris, select = -Species)
y <- Species
model <- svm(x, y, probability = TRUE)
print(model)
summary(model)
pred <- predict(model, x)
# (same as:)
pred <- fitted(model)
library(e1071)
data(iris)
attach(iris)
model <- svm(Species ~ ., data = iris)
x <- subset(iris, select = -Species)
y <- Species
model <- svm(x, y, probability = TRUE)
print(model)
summary(model)
pred <- predict(model, x)
# (same as:)
pred <- fitted(model)
x <- subset(iris, select = -Species)
y <- Species
model <- svm(x, y, probability = TRUE)
model <- svm(Species ~ ., data = iris)
x <- subset(iris, select = -Species)
y <- Species
model <- svm(x, y, probability = TRUE)
print(model)
summary(model)
# test with train data
pred <- predict(model, x)
# (same as:)
pred <- fitted(model)
pred <- predict(model, x, decision.values = TRUE, probability = TRUE)
attr(pred, "decision.values")[1:4,]
attr(pred, "probabilities")[1:4,]
x
model <- svm(x, y, probability = TRUE)
print(model)
summary(model)
pred <- predict(model, x)
pred
svmfit=svm(y~., data=dat, kernel="linear", cost=10)
plot(svmfit,dat)
library(e1071)
set.seed(1)
x=matrix(rnorm(100*2), ncol=2)
y=c(rep(-1,50), rep(1,50),rep(0,100))
x[y==1,]=x[y==1,] + 1
x
y
#Se hace la grÃ¡fica de los puntos generados en el plano
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
#Se construye un Data.Frame
dat=data.frame(x=x, y=as.factor(y))
dat
#Se calcula SVM para el kernel lineal
svmfit=svm(y~., data=dat, kernel="linear", cost=10)
plot(svmfit,dat)
#Se puede revisar los valores y el resumen de los estimado en R project para el modelo SVM
svmfit$index
summary(svmfit)
x=matrix(rnorm(100*2), ncol=2)
y=c(rep(-1,50), rep(1,50)
x[y==1,]=x[y==1,] + 1
x
y
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
dat=data.frame(x=x, y=as.factor(y))
dat
svmfit=svm(y~., data=dat, kernel="linear", cost=10)
plot(svmfit,dat)
library(e1071)
set.seed(1)
x=matrix(rnorm(100*2), ncol=2)
y=c(rep(-1,10), rep(1,10)
x[y==1,]=x[y==1,] + 1
x
y
x=matrix(rnorm(100*2), ncol=2)
y=c(rep(-1,10), rep(1,10))
x[y==1,]=x[y==1,] + 1
x
y
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
#Se construye un Data.Frame
dat=data.frame(x=x, y=as.factor(y))
dat
svmfit=svm(y~., data=dat, kernel="linear", cost=10)
plot(svmfit,dat)
svmfit$index
summary(svmfit)
svmfit=svm(y~., data=dat, kernel="polynomial", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="sigmoid", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="radial", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="linear", cost=10)
plot(svmfit,dat)
svmfit=svm(y~., data=dat, kernel="polynomial", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="sigmoid", cost=10)
plot(svmfit, dat)
svmfit=svm(y~., data=dat, kernel="radial", cost=10)
plot(svmfit, dat)
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
plot(x, col=(9-y),main="Datos mezclados",xlab="Eje X",ylab="Eje y")
#Se construye un Data.Frame
dat=data.frame(x=x, y=as.factor(y))
dat
data <- c('Cats like to chase mice.', 'Dogs like to eat big bones.')
corpus <- VCorpus(VectorSource(data))
corpus
library(ggplot2)
library(stats)
library(dplyr)
library(janeaustenr)
library(tidytext)
book_words <- austen_books() %>%
unnest_tokens(word, text) %>%
count(book, word, sort = TRUE) %>%
ungroup()
total_words <- book_words %>%
group_by(book) %>%
summarize(total = sum(n))
book_words <- left_join(book_words, total_words)
book_words
ggplot(book_words, aes(n/total, fill = book)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~book, ncol = 2, scales = "free_y")
freq_by_rank <- book_words %>%
group_by(book) %>%
mutate(rank = row_number(),
`term frequency` = n/total)
freq_by_rank <- book_words %>%
group_by(book) %>%
mutate(rank = row_number(),
`term frequency` = n/total)
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = book)) +
geom_line(size = 1.2, alpha = 0.8) +
scale_x_log10() +
scale_y_log10()
rank_subset <- freq_by_rank %>%
filter(rank < 500,
rank > 10)
lm(log10(`term frequency`) ~ log10(rank), data = rank_subset)
freq_by_rank %>%
ggplot(aes(rank, `term frequency`, color = book)) +
geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
geom_line(size = 1.2, alpha = 0.8) +
scale_x_log10() +
scale_y_log10()
book_words <- book_words %>%
bind_tf_idf(word, book, n)
book_words
book_words %>%
select(-total) %>%
arrange(desc(tf_idf))
plot_austen <- book_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
plot_austen %>%
top_n(5) %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col() +
labs(x = NULL, y = "tf-idf") +
coord_flip()
plot_austen %>%
top_n(15) %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col() +
labs(x = NULL, y = "tf-idf") +
coord_flip()
plot_austen %>%
group_by(book) %>%
top_n(5) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~book, ncol = 2, scales = "free") +
coord_flip()
plot_austen %>%
group_by(book) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~book, ncol = 2, scales = "free") +
coord_flip()
plot_austen %>%
group_by(book) %>%
top_n(15) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = book)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~book, ncol = 2, scales = "free") +
coord_flip()
library(gutenbergr)
physics <- gutenberg_download(c(37729, 14725, 13476, 5001),
meta_fields = "author")
#***Proceso1
physics_words <- physics %>%
unnest_tokens(word, text) %>%
count(author, word, sort = TRUE) %>%
ungroup()
physics_words
#***Proceso2
physics_words <- physics_words %>%
bind_tf_idf(word, author, n)
#***Proceso3
plot_physics <- physics_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
mutate(author = factor(author, levels = c("Galilei, Galileo",
"Huygens, Christiaan",
"Tesla, Nikola",
"Einstein, Albert")))
plot_physics <- physics_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
mutate(author = factor(author, levels = c("Galilei, Galileo",
"Huygens, Christiaan",
"Tesla, Nikola",
"Einstein, Albert")))
plot_physics %>%
top_n(20) %>%
ggplot(aes(word, tf_idf, fill = author)) +
geom_col() +
labs(x = NULL, y = "tf-idf") +
coord_flip()
plot_physics %>%
group_by(author) %>%
top_n(15, tf_idf) %>%
ungroup() %>%
mutate(word = reorder(word, tf_idf)) %>%
ggplot(aes(word, tf_idf, fill = author)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~author, ncol = 2, scales = "free") +
coord_flip()
ggplot(plot_physics, aes(word, tf_idf, fill = author)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~author, ncol = 2, scales = "free") +
coord_flip()
physics_words <- anti_join(physics_words, mystopwords, by = "word")
physics %>%
filter(str_detect(text, "eq\\.")) %>%
select(text)
library(stringr)
physics %>%
filter(str_detect(text, "eq\\.")) %>%
select(text)
physics %>%
filter(str_detect(text, "K1")) %>%
select(text)
physics %>%
filter(str_detect(text, "AK")) %>%
select(text)
mystopwords <- data_frame(word = c("eq", "co", "rc", "ac", "ak", "bn",
"fig", "file", "cg", "cb", "cm"))
physics_words <- anti_join(physics_words, mystopwords, by = "word")
plot_physics <- physics_words %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word)))) %>%
group_by(author) %>%
top_n(15, tf_idf) %>%
ungroup %>%
mutate(author = factor(author, levels = c("Galilei, Galileo",
"Huygens, Christiaan",
"Tesla, Nikola",
"Einstein, Albert")))
ggplot(plot_physics, aes(word, tf_idf, fill = author)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~author, ncol = 2, scales = "free") +
coord_flip()
library(rvest)
library(xml2)
library(magrittr)
library(stats)
library(dplyr)
require(stringi)
library(magrittr)
library(twitteR)
library(tidyr)
# retrieve emoticons
tweetsback <- userTimeline("Remoticons", n = 900) %>%
twListToDF
# split one column into df with the columns "bytes" and "decription"
tweetsback2 <- data.frame(text = iconv(tweetsback$text, "latin1", "ASCII", "byte"),
stringsAsFactors = FALSE)
# kind of an ugly workaround, but the bytes made it impossible to create a df the proper way
column1 <- separate(tweetsback2, text, into = c("Bytes", "Description"), sep = "\\ ")
column2 <- separate(tweetsback2, text, into = c("Bytes", "Description"), sep = "^[^\\s]*\\s")
df <- data.frame(Bytes = column1$Bytes, Description = column2$Description)
# merge retrieved encoding with original encoding to one df &v write to file
eotw <- merge(alltogether, df, by = "Description")
names(eotw) <- c("Description", "Native", "Bytes", "R-encoding")
write.csv2(eotw, file = "tabladeemoticonos.csv", row.names = FALSE)
options(stringsAsFactors = FALSE)
library(stats)
library(rvest)
library(xml2)
library(magrittr)
library(stats)
library(dplyr)
require(stringi)
library(magrittr)
library(twitteR)
library(tidyr)
# retrieve emoticons
tweetsback <- userTimeline("Remoticons", n = 900) %>%
twListToDF
# split one column into df with the columns "bytes" and "decription"
tweetsback2 <- data.frame(text = iconv(tweetsback$text, "latin1", "ASCII", "byte"),
stringsAsFactors = FALSE)
# kind of an ugly workaround, but the bytes made it impossible to create a df the proper way
column1 <- separate(tweetsback2, text, into = c("Bytes", "Description"), sep = "\\ ")
column2 <- separate(tweetsback2, text, into = c("Bytes", "Description"), sep = "^[^\\s]*\\s")
df <- data.frame(Bytes = column1$Bytes, Description = column2$Description)
# merge retrieved encoding with original encoding to one df &v write to file
eotw <- merge(alltogether, df, by = "Description")
names(eotw) <- c("Description", "Native", "Bytes", "R-encoding")
write.csv2(eotw, file = "tabladeemoticonos.csv", row.names = FALSE)
install.packages("jsonlite")
library(jsonlite)
getwd()
setwd("/home/malusita/karmapulse/checkbotR")
getwd()
library(jsonlite)
archivo <- "checks.json"
archivo
archivo <- "/home/malusita/karmapulse/checkbotR/checks.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
fromJSON(ejemplo_json)
fromJSON(ejemplo_json)
fromJSON(ejemplo_json)
archivo <- "/home/malusita/karmapulse/checkbotR/checks.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
datos <- fromJSON(ejemplo_json)
mydata <- fromJSON("https://gist.githubusercontent.com/briatte/c5a72004359659a287b9/raw/222c77f538cd3a7168423d2830e49bb091c8a29d/gc02a1.json")
install.packages("jsonlite")
install.packages("jsonlite")
getwd()
library(jsonlite)
con <- file(archivo, open="rb")
ejemplo_json <- readLines(con)
archivo <- "/home/malusita/karmapulse/checkbotR/checks.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
close(con)
ejemplo_json <- readLines(con)
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
fromJSON(ejemplo_json)
text <- readLines(curl("https://gist.githubusercontent.com/briatte/c5a72004359659a287b9/raw/222c77f538cd3a7168423d2830e49bb091c8a29d/gc02a1.json"))
library("curl", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.3")
library("RCurl", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.3")
detach("package:RCurl", unload=TRUE)
text <- readLines(curl("https://gist.githubusercontent.com/briatte/c5a72004359659a287b9/raw/222c77f538cd3a7168423d2830e49bb091c8a29d/gc02a1.json"))
library("RCurl", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.3")
archivo <- "/home/malusita/karmapulse/checkbotR/checks_test.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
fromJSON(ejemplo_json)
install.packages("jsonlite")
getwd()
setwd("/home/malusita/karmapulse/checkbotR")
library(jsonlite)
archivo <- "/home/malusita/karmapulse/checkbotR/checks_test.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
archivo <- "/home/malusita/karmapulse/checkbotR/checks_test.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
archivo <- "/home/malusita/karmapulse/checkbotR/checks_test.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
ejemplo_json <- readLines(con)
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
datos <- fromJSON(ejemplo_json)
archivo <- "/home/malusita/karmapulse/checkbotR/checks_test.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
close(con)
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
ejemplo_json <- readLines(con)
datos <- fromJSON(ejemplo_json)
datos <- fromJSON(ejemplo_json)
archivo <- "/home/malusita/karmapulse/checkbotR/checks_test.json"
con <- file(archivo, open="r")
ejemplo_json <- readLines(con)
ejemplo_json <- readLines(con)
close(con)
datos <- fromJSON(ejemplo_json)
